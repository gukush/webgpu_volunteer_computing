// LayerNormChunkingStrategy.js - Layer normalization and residual connections
import { BaseChunkingStrategy } from './base/BaseChunkingStrategy.js';
import fs from 'fs/promises';

export default class LayerNormChunkingStrategy extends BaseChunkingStrategy {
  constructor() {
    super('layer_normalization');
  }

  defineInputSchema() {
    return {
      inputs: [
        { name: 'input_activations', type: 'storage_buffer', binding: 1, elementType: 'f32' },
        { name: 'residual_connection', type: 'storage_buffer', binding: 2, elementType: 'f32' }, // Optional
        { name: 'gamma', type: 'storage_buffer', binding: 3, elementType: 'f32' },
        { name: 'beta', type: 'storage_buffer', binding: 4, elementType: 'f32' }
      ],
      outputs: [
        { name: 'normalized_output', type: 'storage_buffer', binding: 5, elementType: 'f32' }
      ],
      uniforms: [
        {
          name: 'params',
          type: 'uniform_buffer',
          binding: 0,
          fields: [
            { name: 'seq_length', type: 'u32' },
            { name: 'd_model', type: 'u32' },
            { name: 'chunk_start_seq', type: 'u32' },
            { name: 'chunk_seq_length', type: 'u32' },
            { name: 'epsilon', type: 'f32' },
            { name: 'has_residual', type: 'u32' }
          ]
        }
      ]
    };
  }

  planExecution(plan) {
    const { seqLength, dModel, hasResidual = false, epsilon = 1e-5 } = plan.metadata;
    
    if (!seqLength || !dModel) {
      throw new Error("LayerNorm requires 'seqLength' and 'dModel' in metadata");
    }

    // LayerNorm is typically parallelized across sequence dimension
    const seqChunkSize = plan.metadata.seqChunkSize || 256; // Larger chunks for element-wise ops
    const totalChunks = Math.ceil(seqLength / seqChunkSize);

    return {
      strategy: this.name,
      totalChunks,
      assemblyStrategy: 'layer_norm_assembly',
      metadata: {
        ...plan.metadata,
        totalChunks,
        seqChunkSize,
        epsilon,
        hasResidual
      }
    };
  }

  async createChunkDescriptors(plan) {
    const { seqLength, dModel, seqChunkSize, epsilon, hasResidual } = plan.metadata;
    const framework = plan.framework || 'webgpu';

    // Get input files
    const inputRef = (plan.inputRefs || []).find(r => r.name === 'input_activations');
    const residualRef = hasResidual ? (plan.inputRefs || []).find(r => r.name === 'residual_connection') : null;
    const gammaRef = (plan.inputRefs || []).find(r => r.name === 'gamma');
    const betaRef = (plan.inputRefs || []).find(r => r.name === 'beta');

    if (!inputRef || !gammaRef || !betaRef) {
      throw new Error('LayerNorm requires input_activations, gamma, and beta files');
    }

    if (hasResidual && !residualRef) {
      throw new Error('hasResidual=true but no residual_connection file provided');
    }

    const descriptors = [];
    const seqChunks = Math.ceil(seqLength / seqChunkSize);
    
    for (let seqIdx = 0; seqIdx < seqChunks; seqIdx++) {
      const seqStart = seqIdx * seqChunkSize;
      const seqEnd = Math.min((seqIdx + 1) * seqChunkSize, seqLength);
      const actualSeqLength = seqEnd - seqStart;

      const descriptor = await this.createLayerNormChunkDescriptor(
        framework, seqIdx, seqStart, actualSeqLength,
        plan, inputRef, residualRef, gammaRef, betaRef
      );
      descriptors.push(descriptor);
    }

    return descriptors;
  }

  async createLayerNormChunkDescriptor(
    framework, chunkIndex, seqStart, seqLength,
    plan, inputRef, residualRef, gammaRef, betaRef
  ) {
    const { dModel, epsilon, hasResidual } = plan.metadata;
    
    // Read input activations for this sequence chunk
    const inputData = await this.readFileSection(inputRef, seqStart * dModel * 4, seqLength * dModel * 4);
    
    // Read residual connection data if needed
    let residualData = null;
    if (hasResidual && residualRef) {
      residualData = await this.readFileSection(residualRef, seqStart * dModel * 4, seqLength * dModel * 4);
    }

    // Layer norm parameters (same for all chunks)
    const gammaData = await this.readFileSection(gammaRef, 0, dModel * 4);
    const betaData = await this.readFileSection(betaRef, 0, dModel * 4);

    const outputSize = seqLength * dModel * 4; // Float32 bytes

    const inputs = [
      { name: 'input_activations', data: inputData.toString('base64') }
    ];

    if (hasResidual && residualData) {
      inputs.push({ name: 'residual_connection', data: residualData.toString('base64') });
    } else {
      // Provide empty residual data if not used
      inputs.push({ name: 'residual_connection', data: Buffer.alloc(seqLength * dModel * 4).toString('base64') });
    }

    inputs.push({ name: 'gamma', data: gammaData.toString('base64') });
    inputs.push({ name: 'beta', data: betaData.toString('base64') });

    const baseDescriptor = {
      chunkId: `layernorm-s${seqStart}`,
      chunkIndex,
      parentId: plan.parentId,
      framework,
      inputs,
      outputs: [{ name: 'normalized_output', size: outputSize }],
      metadata: {
        seq_length: plan.metadata.seqLength,
        d_model: dModel,
        chunk_start_seq: seqStart,
        chunk_seq_length: seqLength,
        epsilon: epsilon,
        has_residual: hasResidual ? 1 : 0
      },
      assemblyMetadata: {
        seqStart,
        seqLength,
        outputSize
      }
    };

    return this.addFrameworkSpecificCode(baseDescriptor, framework);
  }

  addFrameworkSpecificCode(baseDescriptor, framework) {
    switch (framework) {
      case 'webgpu':
        return {
          ...baseDescriptor,
          kernel: this.getWebGPUShader(),
          entry: 'main',
          workgroupCount: [
            Math.ceil(baseDescriptor.metadata.chunk_seq_length / 64),
            1,
            1
          ]
        };

      case 'webgl':
        return {
          ...baseDescriptor,
          webglShaderType: 'transform_feedback',
          webglVertexShader: this.getWebGLVertexShader(),
          webglFragmentShader: this.getWebGLFragmentShader(),
          webglVaryings: ['v_norm_out'],
          webglNumElements: baseDescriptor.metadata.chunk_seq_length * baseDescriptor.metadata.d_model,
          webglInputSpec: { type: 'texture', format: 'float32', internalFormat: 'R32F' }
        };

      case 'javascript':
        return {
          ...baseDescriptor,
          kernel: this.getJavaScriptKernel(),
          entry: 'layerNormalization',
          jsExecutionHints: { algorithm: 'layer_normalization', parallelizable: true }
        };

      default:
        throw new Error(`Unsupported framework: ${framework}`);
    }
  }

  async readFileSection(fileRef, offset, length) {
    if (fileRef.path) {
      const fileHandle = await fs.open(fileRef.path, 'r');
      try {
        const buffer = Buffer.alloc(length);
        await fileHandle.read(buffer, 0, length, offset);
        return buffer;
      } finally {
        await fileHandle.close();
      }
    } else {
      throw new Error('File path not provided');
    }
  }

  getWebGPUShader() {
    return `
      struct LayerNormParams {
        seq_length: u32,
        d_model: u32,
        chunk_start_seq: u32,
        chunk_seq_length: u32,
        epsilon: f32,
        has_residual: u32,
      }

      @group(0) @binding(0) var<uniform> params: LayerNormParams;
      @group(0) @binding(1) var<storage, read> input_activations: array<f32>;
      @group(0) @binding(2) var<storage, read> residual_connection: array<f32>;
      @group(0) @binding(3) var<storage, read> gamma: array<f32>;
      @group(0) @binding(4) var<storage, read> beta: array<f32>;
      @group(0) @binding(5) var<storage, read_write> normalized_output: array<f32>;

      @compute @workgroup_size(64, 1, 1)
      fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
        let seq_idx = gid.x;
        
        if (seq_idx >= params.chunk_seq_length) {
          return;
        }

        let base_idx = seq_idx * params.d_model;

        // Step 1: Apply residual connection if enabled
        var activations = array<f32, 512>(); // Assuming max d_model = 512
        for (var d = 0u; d < params.d_model; d++) {
          activations[d] = input_activations[base_idx + d];
          if (params.has_residual == 1u) {
            activations[d] += residual_connection[base_idx + d];
          }
        }

        // Step 2: Compute mean
        var sum = 0.0;
        for (var d = 0u; d < params.d_model; d++) {
          sum += activations[d];
        }
        let mean = sum / f32(params.d_model);

        // Step 3: Compute variance
        var var_sum = 0.0;
        for (var d = 0u; d < params.d_model; d++) {
          let diff = activations[d] - mean;
          var_sum += diff * diff;
        }
        let variance = var_sum / f32(params.d_model);
        let std_dev = sqrt(variance + params.epsilon);

        // Step 4: Normalize and scale
        for (var d = 0u; d < params.d_model; d++) {
          let normalized = (activations[d] - mean) / std_dev;
          let scaled = normalized * gamma[d] + beta[d];
          normalized_output[base_idx + d] = scaled;
        }
      }
    `;
  }

  getWebGLVertexShader() {
    return `#version 300 es
      precision highp float;
      
      in float a_index;
      uniform int u_seq_length;
      uniform int u_d_model;
      uniform int u_chunk_start_seq;
      uniform int u_chunk_seq_length;
      uniform float u_epsilon;
      uniform int u_has_residual;
      
      uniform sampler2D u_input_0; // input_activations
      uniform sampler2D u_input_1; // residual_connection  
      uniform sampler2D u_input_2; // gamma
      uniform sampler2D u_input_3; // beta

      out float v_norm_out;

      void main() {
        int idx = int(a_index);
        int seq_idx = idx / u_d_model;
        int d_idx = idx % u_d_model;
        
        if (seq_idx >= u_chunk_seq_length) {
          v_norm_out = 0.0;
          gl_Position = vec4(0.0);
          return;
        }

        // Compute mean for this sequence position (simplified for WebGL)
        float sum = 0.0;
        for (int d = 0; d < u_d_model; d++) {
          vec2 coord = vec2(float(d), float(seq_idx));
          float val = texelFetch(u_input_0, ivec2(coord), 0).r;
          
          if (u_has_residual == 1) {
            val += texelFetch(u_input_1, ivec2(coord), 0).r;
          }
          
          if (d == d_idx) {
            sum = val; // Store current value for later use
          }
        }
        
        // Simplified normalization (full implementation would require two passes)
        vec2 gamma_coord = vec2(float(d_idx), 0.0);
        vec2 beta_coord = vec2(float(d_idx), 0.0);
        float gamma_val = texelFetch(u_input_2, ivec2(gamma_coord), 0).r;
        float beta_val = texelFetch(u_input_3, ivec2(beta_coord), 0).r;
        
        // Simplified normalization (assuming mean=0, std=1 for WebGL)
        v_norm_out = sum * gamma_val + beta_val;
        gl_Position = vec4(0.0);
      }
    `;
  }

  getWebGLFragmentShader() {
    return `#version 300 es
      precision highp float;
      out vec4 fragColor;
      void main() { fragColor = vec4(1.0); }
    `;
  }

  getJavaScriptKernel() {
    return `
      function layerNormalization(inputActivations, residualConnection, gamma, beta, metadata) {
        const {
          seq_length, d_model, chunk_start_seq, chunk_seq_length,
          epsilon, has_residual
        } = metadata;

        const inputFloats = new Float32Array(inputActivations.buffer);
        const residualFloats = new Float32Array(residualConnection.buffer);
        const gammaFloats = new Float32Array(gamma.buffer);
        const betaFloats = new Float32Array(beta.buffer);

        const outputSize = chunk_seq_length * d_model;
        const output = new Float32Array(outputSize);

        // Layer normalization with optional residual connection
        for (let seq = 0; seq < chunk_seq_length; seq++) {
          const seqOffset = seq * d_model;
          
          // Step 1: Apply residual connection and compute mean
          let sum = 0;
          const activations = new Float32Array(d_model);
          
          for (let d = 0; d < d_model; d++) {
            const idx = seqOffset + d;
            activations[d] = inputFloats[idx];
            
            if (has_residual) {
              activations[d] += residualFloats[idx];
            }
            
            sum += activations[d];
          }
          
          const mean = sum / d_model;
          
          // Step 2: Compute variance
          let varSum = 0;
          for (let d = 0; d < d_model; d++) {
            const diff = activations[d] - mean;
            varSum += diff * diff;
          }
          
          const variance = varSum / d_model;
          const stdDev = Math.sqrt(variance + epsilon);
          
          // Step 3: Normalize and scale
          for (let d = 0; d < d_model; d++) {
            const normalized = (activations[d] - mean) / stdDev;
            const scaled = normalized * gammaFloats[d] + betaFloats[d];
            output[seqOffset + d] = scaled;
          }
        }

        return output;
      }
    `;
  }
}
